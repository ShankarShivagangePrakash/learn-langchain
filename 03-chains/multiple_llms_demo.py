"""
    Multi-LLM Sequential Chain Demo - Hybrid AI Model Integration

    FUNCTIONAL OVERVIEW:
    This application demonstrates a powerful pattern of using MULTIPLE different LLMs 
    in a single sequential chain workflow:
        1. First chain: Uses OpenAI GPT-4o (commercial model) for title generation
        2. Second chain: Uses Mistral via Ollama (open-source model) for speech writing

    KEY ADVANTAGES OF MULTI-LLM APPROACH:
        - Cost Optimization: Use expensive models only where their capabilities are crucial
        - Performance Optimization: Leverage each model's specific strengths
        - Fallback Strategy: If one model fails, the other can continue
        - Diversity: Different models bring varied perspectives and writing styles

    CHAIN FLOW:
    Topic → GPT-4o (Title) → Mistral (Speech) → Combined Output

    USE CASE SCENARIOS:
        - Title generation requires creativity (GPT-4o strength)
        - Speech writing benefits from open-source model efficiency (Mistral)
        - Cost-effective solution for production applications
        - Experimentation with different model combinations

    TECHNICAL CONCEPTS DEMONSTRATED:
        - Multi-model integration in single workflow
        - Hybrid commercial/open-source model usage
        - Local vs. API-based model coordination
        - Model-specific optimization strategies
"""

import os
from langchain_openai import ChatOpenAI
import streamlit as st
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_models import ChatOllama

# ENVIRONMENT CONFIGURATION
# OpenAI requires API key for commercial model access
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

"""
    MULTI-LLM SETUP: Two Different Model Types
    LLM 1: Commercial Model (OpenAI GPT-4o)
    - Strengths: Advanced reasoning, creativity, complex language understanding
    - Use case: High-quality title generation requiring nuanced understanding
    - Cost: Higher per token, but excellent for creative tasks
"""
llm1 = ChatOpenAI(model="gpt-4o", api_key=OPENAI_API_KEY)

"""
    LLM 2: Open Source Model (Mistral via Ollama)
    - Strengths: Fast inference, cost-effective, privacy-friendly (runs locally)
    - Use case: Structured content generation like speech writing
    - Cost: Free to run locally, but requires local setup
    - Note: Requires Ollama to be installed and Mistral model downloaded locally
"""
llm2 = ChatOllama(model="mistral")
# PROMPT TEMPLATES: Optimized for Each Model's Strengths

# Title Generation Prompt: Leverages GPT-4o's creative capabilities
# Designed for the commercial model's superior understanding of nuance
title_prompt = PromptTemplate(
    input_variables=["topic"],
    template="""You are an experienced speech writer.
    You need to craft an impactful title for a speech 
    on the following topic: {topic}
    Answer exactly with one title.	
    """
)

# Speech Writing Prompt: Optimized for Mistral's structured generation
# Focuses on clear, structured content generation where open-source models excel
speech_prompt = PromptTemplate(
    input_variables=["title"],
    template="""You need to write a powerful speech of 350 words
     for the following title: {title}
    """
)

"""
    HYBRID CHAIN CONSTRUCTION: Strategic Model Assignment

    First Chain: Topic → GPT-4o → Title Generation → Display → Pass Title
    Technical Decision: Use GPT-4o for title creation because:
    1. Titles require high creativity and nuanced understanding
    2. GPT-4o excels at concise, impactful language generation
    3. Cost is minimal for short outputs like titles
"""
first_chain = title_prompt | llm1 | StrOutputParser() | (lambda title: (st.write(title), title)[1])

"""
    Second Chain: Title → Mistral → Speech Generation
    Technical Decision: Use Mistral for speech writing because:
    1. Longer content generation is cost-effective with open-source models
    2. Mistral handles structured content well
    3. Reduces API costs for bulk content generation
"""
second_chain = speech_prompt | llm2

# FINAL MULTI-LLM SEQUENTIAL CHAIN
# Flow: Input → Commercial Model → Open Source Model → Output
# Benefits: Combines best of both worlds - creativity + efficiency
final_chain = first_chain | second_chain

# STREAMLIT USER INTERFACE
st.title("Speech Generator")

# USER INPUT COLLECTION
topic = st.text_input("Enter the topic:")

# EXECUTION LOGIC: Multi-Model Chain Processing
if topic:
    # Execute the hybrid multi-LLM sequential chain
    # Step 1: topic → GPT-4o (creates engaging title)
    # Step 2: title → Mistral (generates full speech content)
    response = final_chain.invoke({"topic": topic})
    
    # Display the final speech generated by the open-source model
    # Technical Note: response.content contains Mistral's generated speech
    st.write("**Generated Speech (Powered by Multiple AI Models):**")
    st.write(response.content)